# English Reading Comprehension with Logical Reasoning

## Overview
This repository contains code and resources for leveraging mT5 and T5 models for English Reading Comprehension Based Question Answering with Logical Reasoning using the LogiQA dataset. The LogiQA dataset comprises 8,678 QA instances sourced from expert-written questions designed to evaluate human logical reasoning skills across various deductive reasoning types.


## Introduction
In this project, I explore the capabilities of mT5 and T5 models in tackling English Reading Comprehension tasks that involve logical reasoning. The aim is to provide a comprehensive framework for answering questions based on the LogiQA dataset, which encompasses a wide array of deductive reasoning scenarios.

## Dataset
- **LogiQA Dataset**: The LogiQA dataset (available [here](https://github.com/lgw863/LogiQA-dataset)) serves as the cornerstone of this project, comprising 8,678 QA instances meticulously crafted to test various aspects of logical reasoning.

## Models
- **mT5 and T5**: We leverage the Hugging Face Transformers library to employ the mT5 and T5 models for English Reading Comprehension tasks with logical reasoning. These models offer state-of-the-art natural language understanding and generation capabilities.

## Usage
To replicate our experiments or use the code:
1. Clone this repository.
2. Install the necessary dependencies specified in `requirements.txt`.
3. Utilize the provided scripts and notebooks to train, fine-tune, or evaluate the mT5 and T5 models on the LogiQA dataset.


